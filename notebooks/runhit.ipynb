{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "RDKit WARNING: [00:45:05] Enabling RDKit 2019.09.2 jupyter extensions\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Load data\n",
    "from src.data import make_dataset\n",
    "molecules=make_dataset.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Build the features\n",
    "from src.features import build_features\n",
    "X=build_features.build(molecules)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Processed 32 hits.\n",
      "Matched 32 hits\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Build the targets\n",
    "from src.features import build_targets\n",
    "y=build_targets.build_hit(molecules)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Fraction hits: train: 0.031, test: 0.036\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Create train/test sets\n",
    "from src.models import split_data\n",
    "X_train, X_test, y_train, y_test, ind_train, ind_test = split_data.split(0.4,X,y,seed)\n",
    "mol_test=[molecules[x] for x in ind_test]\n",
    "mol_train=[molecules[x] for x in ind_train]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Cross-validation score = 0.809 += 0.114\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=10, n_jobs=None, oob_score=False,\n",
      "                       random_state=42, verbose=0, warm_start=False)\n",
      "Cross-validation score = 0.832 += 0.100\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Train model\n",
    "from src.models import train_model\n",
    "models=[train_model.train_lr(X_train,y_train,seed),train_model.train_rfc(X_train,y_train,seed,n_estimators=10)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "------\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       558\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00       576\n",
      "   macro avg       1.00      1.00      1.00       576\n",
      "weighted avg       1.00      1.00      1.00       576\n",
      "\n",
      "[[558   0]\n",
      " [  0  18]]\n",
      "ROC_AUC Score = 1.000\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99       370\n",
      "         1.0       0.67      0.57      0.62        14\n",
      "\n",
      "    accuracy                           0.97       384\n",
      "   macro avg       0.83      0.78      0.80       384\n",
      "weighted avg       0.97      0.97      0.97       384\n",
      "\n",
      "[[366   4]\n",
      " [  6   8]]\n",
      "ROC_AUC Score = 0.780\n",
      "  91A2: predict=0.0, actual=1.0\n",
      "  31E3: predict=0.0, actual=1.0\n",
      " 101C8: predict=1.0, actual=0.0\n",
      "  91B2: predict=0.0, actual=1.0\n",
      "  41F3: predict=0.0, actual=1.0\n",
      " 101E6: predict=0.0, actual=1.0\n",
      "   1A4: predict=0.0, actual=1.0\n",
      " 101D7: predict=1.0, actual=0.0\n",
      "  51F8: predict=1.0, actual=0.0\n",
      "  91E3: predict=1.0, actual=0.0\n",
      "LOO:\n",
      "Running Leave-out validation on 960 molecules...\n",
      "0...\n",
      "   1A4: predict=0.0, actual=1.0\n",
      "20...40...60...80...100...120...140...160...180...200...220...240...\n",
      "  31B9: predict=1.0, actual=0.0\n",
      "260...\n",
      "  31D8: predict=0.0, actual=1.0\n",
      "280...\n",
      "  31E3: predict=0.0, actual=1.0\n",
      "\n",
      "  31E4: predict=1.0, actual=0.0\n",
      "300...320...340...\n",
      "  41C3: predict=1.0, actual=0.0\n",
      "\n",
      "  41C7: predict=1.0, actual=0.0\n",
      "360...\n",
      "  41F3: predict=0.0, actual=1.0\n",
      "380...\n",
      "  41G7: predict=1.0, actual=0.0\n",
      "400...420...440...\n",
      "  51F8: predict=1.0, actual=0.0\n",
      "460...\n",
      "  51H8: predict=0.0, actual=1.0\n",
      "480...500...520...540...560...580...600...620...640...660...680...700...720...740...760...\n",
      "  91E3: predict=1.0, actual=0.0\n",
      "\n",
      "  91F3: predict=1.0, actual=0.0\n",
      "\n",
      "  91F5: predict=0.0, actual=1.0\n",
      "780...\n",
      "  91G3: predict=1.0, actual=0.0\n",
      "800...820...\n",
      " 101D7: predict=1.0, actual=0.0\n",
      "840...\n",
      " 101E6: predict=0.0, actual=1.0\n",
      "\n",
      "101E10: predict=0.0, actual=1.0\n",
      "\n",
      " 101F6: predict=1.0, actual=0.0\n",
      "860...\n",
      " 101G6: predict=0.0, actual=1.0\n",
      "\n",
      " 101G7: predict=1.0, actual=0.0\n",
      "880...900...920...940...done\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       928\n",
      "         1.0       0.66      0.72      0.69        32\n",
      "\n",
      "    accuracy                           0.98       960\n",
      "   macro avg       0.82      0.85      0.84       960\n",
      "weighted avg       0.98      0.98      0.98       960\n",
      "\n",
      "[[916  12]\n",
      " [  9  23]]\n",
      "ROC_AUC Score = 0.853\n",
      "------\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=10, n_jobs=None, oob_score=False,\n",
      "                       random_state=42, verbose=0, warm_start=False)\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       558\n",
      "         1.0       1.00      0.89      0.94        18\n",
      "\n",
      "    accuracy                           1.00       576\n",
      "   macro avg       1.00      0.94      0.97       576\n",
      "weighted avg       1.00      1.00      1.00       576\n",
      "\n",
      "[[558   0]\n",
      " [  2  16]]\n",
      "ROC_AUC Score = 0.944\n",
      "101E10: predict=0.0, actual=1.0\n",
      "  31E9: predict=0.0, actual=1.0\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       370\n",
      "         1.0       1.00      0.43      0.60        14\n",
      "\n",
      "    accuracy                           0.98       384\n",
      "   macro avg       0.99      0.71      0.79       384\n",
      "weighted avg       0.98      0.98      0.98       384\n",
      "\n",
      "[[370   0]\n",
      " [  8   6]]\n",
      "ROC_AUC Score = 0.714\n",
      "  31E3: predict=0.0, actual=1.0\n",
      "  41D7: predict=0.0, actual=1.0\n",
      " 101G6: predict=0.0, actual=1.0\n",
      "  91B2: predict=0.0, actual=1.0\n",
      "  41F3: predict=0.0, actual=1.0\n",
      " 101E6: predict=0.0, actual=1.0\n",
      "   1A4: predict=0.0, actual=1.0\n",
      "  91C2: predict=0.0, actual=1.0\n",
      "LOO:\n",
      "Running Leave-out validation on 960 molecules...\n",
      "0...\n",
      "   1A4: predict=0.0, actual=1.0\n",
      "20...40...60...80...100...120...140...160...180...200...220...240...260...\n",
      "  31D8: predict=0.0, actual=1.0\n",
      "280...\n",
      "  31E3: predict=0.0, actual=1.0\n",
      "\n",
      "  31E9: predict=0.0, actual=1.0\n",
      "300...320...340...\n",
      "  41C7: predict=1.0, actual=0.0\n",
      "\n",
      "  41D7: predict=0.0, actual=1.0\n",
      "360...\n",
      "  41F3: predict=0.0, actual=1.0\n",
      "\n",
      "  41F7: predict=0.0, actual=1.0\n",
      "380...\n",
      "  41G7: predict=1.0, actual=0.0\n",
      "\n",
      "  41H7: predict=0.0, actual=1.0\n",
      "400...420...440...\n",
      "  51F8: predict=1.0, actual=0.0\n",
      "460...\n",
      "  51H8: predict=0.0, actual=1.0\n",
      "480...500...520...540...560...580...600...620...640...660...680...700...720...740...760...\n",
      "  91E3: predict=1.0, actual=0.0\n",
      "\n",
      "  91F3: predict=1.0, actual=0.0\n",
      "\n",
      "  91F4: predict=0.0, actual=1.0\n",
      "\n",
      "  91F5: predict=0.0, actual=1.0\n",
      "780...\n",
      "  91G3: predict=1.0, actual=0.0\n",
      "\n",
      "  91G4: predict=0.0, actual=1.0\n",
      "800...820...840...\n",
      " 101E6: predict=0.0, actual=1.0\n",
      "\n",
      "101E10: predict=0.0, actual=1.0\n",
      "860...\n",
      " 101G6: predict=0.0, actual=1.0\n",
      "\n",
      " 101G7: predict=1.0, actual=0.0\n",
      "\n",
      " 101H6: predict=0.0, actual=1.0\n",
      "880...900...920...940...done\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99       928\n",
      "         1.0       0.70      0.50      0.58        32\n",
      "\n",
      "    accuracy                           0.98       960\n",
      "   macro avg       0.84      0.75      0.78       960\n",
      "weighted avg       0.97      0.98      0.97       960\n",
      "\n",
      "[[921   7]\n",
      " [ 16  16]]\n",
      "ROC_AUC Score = 0.746\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Test model\n",
    "from src.models import predict_model\n",
    "for model in models:\n",
    "    print(\"------\")\n",
    "    print(model)\n",
    "    print(\"Train:\")\n",
    "    yp_train=predict_model.predict(model,X_train,y_train,mol_train)\n",
    "    print(\"Test:\")\n",
    "    yp_test=predict_model.predict(model,X_test,y_test,mol_test)\n",
    "    print(\"LOO:\")\n",
    "    yp_loo=predict_model.predictLOO(model,X,y,molecules)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}